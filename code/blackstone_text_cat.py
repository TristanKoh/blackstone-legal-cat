from pathlib import Path
import pandas as pd

# This depends on your working directory: import os then run os.getcwd() to check, change path as necessary
dataFilePath = Path("blackstone-legal-cat", "data", "spandeck.txt")

spandeck = open(dataFilePath, "r", encoding = "utf8")

# This returns a stream (i.e. generator object), save it to list
text = spandeck.readlines()

# Text preprocessing
def text_preprocessing(text):
    """ Accepts a list of unprocessed strings, returns a list of strings without string and tab breaks and empty strings """
    
    processed_text = []

    for string in text:
        string = string.replace("\n", "")
        string = string.replace("\t", " ")
        processed_text.append(string)
    
    processed_text = [string for string in processed_text if string != ""]

    return processed_text

text = text_preprocessing(text)

# Since blackstone categoriser works at a sentence level, split the strings into individual sentences using model's sentence boundary detector
import spacy
nlp = spacy.load("en_blackstone_proto")

def legal_cats(sentences):
    """
    Function to identify the highest scoring category prediction generated by the text categoriser. 

    Arguments: 
    a list of strings
    
    converts to spacy generator object, splits into sentences using spacy's sentence detector

    returns a tuple of: 
    a list of the split sentences,
    a list of the max cat and max score for each doc in tuples
    """
    doc_sentences = []

    docs = nlp.pipe(sentences, disable = ["tagger", "ner", "textcat"])

    for doc in docs:
        for sentence in doc.sents:
            doc_sentences.append(sentence.text)
    
    docs = nlp.pipe(doc_sentences, disable = ["tagger", "parser", "ner"])
    cats_list = []

    for doc in docs:
        cats = doc.cats
        max_score = max(cats.values()) 
        max_cats = [k for k, v in cats.items() if v == max_score]
        max_cat = max_cats[0]
        cats_list.append((max_cat, max_score))

    return doc_sentences, cats_list

cats = legal_cats(text)

# Append each sentence to dataframe
df = pd.DataFrame({"sentence" : cats[0], "category": [cat[0] for cat in cats[1]], "score": [cat[1] for cat in cats[1]]})

df.head()

df["category"].unique()

for sentence in df.loc[df["category"] == "LEGAL_TEST", "sentence"][:30]:
    print(sentence)
    print("-" * 40)

df.head()

# df.to_csv(r"C:\\Users\\Tristan\\Desktop\\Projects\\blackstone\\data\\df.csv", index = False, encoding = "utf-8-sig")
